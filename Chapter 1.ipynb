{

  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deepak-Jeron-9-7-2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl0eiIMMLTipmAju03iTvx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f856b1e61de4953912081d2bdd5af83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80df564462f94c619ef8a42ff1cced81",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47845f76e881412083a2c4480f4e6f1b",
              "IPY_MODEL_f44f51314f73439f89a9fd4214b6915f"
            ]
          }
        },
        "80df564462f94c619ef8a42ff1cced81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47845f76e881412083a2c4480f4e6f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7ea77c6502c412db0bae7fb9065c833",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e4db3979cb14b5e928a926fa7ed018f"
          }
        },
        "f44f51314f73439f89a9fd4214b6915f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab0f5eb3d6fc416d900ee12d3fb9199a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:02&lt;00:00,  1.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_312f63a6c2224f679f08ae1adad88241"
          }
        },
        "e7ea77c6502c412db0bae7fb9065c833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e4db3979cb14b5e928a926fa7ed018f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab0f5eb3d6fc416d900ee12d3fb9199a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "312f63a6c2224f679f08ae1adad88241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2981276c15eb43a2b1bc59a235f622bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94974fbc9b19403e9dd9cf5888e8a627",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ebefb625f2a4d7f9a286340af7c3a15",
              "IPY_MODEL_389e75b7c85d46d0b5a145da27b245aa"
            ]
          }
        },
        "94974fbc9b19403e9dd9cf5888e8a627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ebefb625f2a4d7f9a286340af7c3a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8daf2c8589b24dad89595cb1dfc876c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8bde308787b49a8881ec3a0ddcc5058"
          }
        },
        "389e75b7c85d46d0b5a145da27b245aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_666f5712ddb44e26b428dcc6106242c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:04&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_368d29bfbf774784901f6f0352201625"
          }
        },
        "8daf2c8589b24dad89595cb1dfc876c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8bde308787b49a8881ec3a0ddcc5058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "666f5712ddb44e26b428dcc6106242c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "368d29bfbf774784901f6f0352201625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "507444a8d1494c789f6160642bf10f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55a67ac9a7864eda8197811e5456316b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88784208d1c644d68cb4ea576ae311c7",
              "IPY_MODEL_a91b3f3689ec47dbb1e0f28b1a2871e8"
            ]
          }
        },
        "55a67ac9a7864eda8197811e5456316b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88784208d1c644d68cb4ea576ae311c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86f75dec5832404ab53ca82fb5af5176",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_525e3711a4964948851260cbc72a0acb"
          }
        },
        "a91b3f3689ec47dbb1e0f28b1a2871e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97b9506da0a74a6d8355979e33ea2b31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:02&lt;00:00,  2.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d541031bf3fc43aeac6aea9eaddc44c1"
          }
        },
        "86f75dec5832404ab53ca82fb5af5176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "525e3711a4964948851260cbc72a0acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97b9506da0a74a6d8355979e33ea2b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d541031bf3fc43aeac6aea9eaddc44c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2394c113a0da4fe0becadaf89fdf2a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b118f16f20e49b199f5d0baf898d9a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd2a9de0819b48c9b2f3306b2d4e71db",
              "IPY_MODEL_dbdce226d3134eec9718f4f17dcbc00f"
            ]
          }
        },
        "9b118f16f20e49b199f5d0baf898d9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd2a9de0819b48c9b2f3306b2d4e71db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c08d2596bda444fdbb26d3649fb40636",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b05ff7334f544b4bdf2dd957260cfad"
          }
        },
        "dbdce226d3134eec9718f4f17dcbc00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_219df13d0d094e70b9682efd5534f07d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:05&lt;00:00,  1.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3226ff6c3814512b674a4ba116254c0"
          }
        },
        "c08d2596bda444fdbb26d3649fb40636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b05ff7334f544b4bdf2dd957260cfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "219df13d0d094e70b9682efd5534f07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3226ff6c3814512b674a4ba116254c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerondeepak/Project-ML/blob/main/Deepak_Jeron_9_7_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwo-CpCIkyg1"
      },
      "source": [
        "**NFH and NFL prediction in given dataset  Using Autogluon TabularPredictor**\n",
        "\n",
        "\n",
        "step 1 : *data preprocessing*  split given dataset into two  dataset  with occurs NFH and NFL into two dataset and Normalize them .\n",
        "\n",
        "step 2: *HPO* , using eval_metric = 'mean_squared_error'  because , its a regression type . then tune the parameters\n",
        "\n",
        "step 3: display summary\n",
        "\n",
        "step 4: *Model ensembling with stacking/bagging*\n",
        "\n",
        "step 5: load model\n",
        "\n",
        "step 6: *Model distillation* \n",
        "\n",
        "\n",
        "**NFH**\n",
        "Fitting model: ExtraTreesMSE \n",
        "\t-2974.5727\t = Validation mean_squared_error score\n",
        "\n",
        "\n",
        "**NFL**\n",
        "\n",
        "Fitting model: RandomForestMSE\n",
        "\t-9403.1067\t = Validation mean_squared_error \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hunLgsNTea_e",
        "outputId": "4e248bdf-bfa8-455e-919a-df83a1584abc"
      },
      "source": [
        "# Uninstall mkl for faster neural-network training time\n",
        "!pip uninstall -y mkl\n",
        "# Upgrade pip to ensure the latest package versions are available\n",
        "!pip install -U pip\n",
        "# Upgrade setuptools to be compatible with namespace packages\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "# Install autogluon (Tutorial based on autogluon==0.1.0)\n",
        "!pip install autogluon\n",
        "# Upgrade ipykernel (Necessary for Colab)\n",
        "\n",
        "!pip install -U ipykernel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping mkl as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: mxnet<2.0.0 in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: autogluon.vision==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.mxnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.extra==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.text==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.core==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: autogluon.features==0.2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn<0.25,>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (0.24.2)\n",
            "Requirement already satisfied: distributed>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (2021.7.0)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (5.1.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: scipy<1.7,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (1.6.3)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (2021.7.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (1.17.112)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (0.3.3)\n",
            "Requirement already satisfied: ConfigSpace==0.4.18 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (0.4.18)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (2.7.2)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (4.41.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (0.29.23)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.2.0->autogluon) (3.6.4)\n",
            "Requirement already satisfied: gluoncv<0.11,>=0.10.1.post0 in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.2.0->autogluon) (0.10.3)\n",
            "Requirement already satisfied: openml in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.2.0->autogluon) (0.12.2)\n",
            "Requirement already satisfied: Pillow<=8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.2.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: psutil<5.9,>=5.7.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (5.8.0)\n",
            "Requirement already satisfied: xgboost<1.4,>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: lightgbm<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (3.2.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (1.9.0+cu102)\n",
            "Requirement already satisfied: fastai<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: catboost<0.26,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon) (0.25.1)\n",
            "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20210201 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.2.0->autogluon) (0.0.1b20210201)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.2.0->autogluon) (3.0.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.1.8)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.1.95)\n",
            "Requirement already satisfied: contextvars in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (2.4)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (3.9.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (1.5.1)\n",
            "Requirement already satisfied: sacremoses>=0.0.38 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.0.45)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (3.17.3)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.9.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (2019.12.20)\n",
            "Requirement already satisfied: d8<1.0,>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.2.0->autogluon) (0.0.2.post0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.18->autogluon.core==0.2.0->autogluon) (2.4.7)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.2.0->autogluon) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon) (4.4.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon) (1.5.12)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon) (2021.7.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon) (3.13)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon) (1.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.2.0->autogluon) (0.11.1)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (57.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (1.7.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (2.4.0)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.3.20)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (21.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (20.9)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (0.10.0+cu102)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (2.2.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11,>=0.10.1.post0->autogluon.extra==0.2.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11,>=0.10.1.post0->autogluon.extra==0.2.0->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11,>=0.10.1.post0->autogluon.extra==0.2.0->autogluon) (0.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.2.0->autogluon) (0.36.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.2.0->autogluon) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon) (2.8.1)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.2.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.2.0->autogluon) (3.4.7)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.2.0->autogluon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon) (2.20)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.2.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.2.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon) (2.10)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.2.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.2.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.112 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.2.0->autogluon) (1.20.112)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.2.0->autogluon) (0.10.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.7/dist-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.15)\n",
            "Requirement already satisfied: pycodestyle<2.8.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (2.7.0)\n",
            "Requirement already satisfied: pyflakes<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (2.3.1)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon) (0.6.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon) (5.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.2.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.2.0->autogluon) (0.10.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.2.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.2.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.2.0->autogluon) (7.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon) (21.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon) (8.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon) (1.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: importlib-metadata<4 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (3.10.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.0.5)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (7.25.0)\n",
            "Requirement already satisfied: debugpy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel) (3.7.4.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (57.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.19)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.18.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.1.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (4.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (22.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdoo8359XViB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ptB3lbRuY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7f856b1e61de4953912081d2bdd5af83",
            "80df564462f94c619ef8a42ff1cced81",
            "47845f76e881412083a2c4480f4e6f1b",
            "f44f51314f73439f89a9fd4214b6915f",
            "e7ea77c6502c412db0bae7fb9065c833",
            "6e4db3979cb14b5e928a926fa7ed018f",
            "ab0f5eb3d6fc416d900ee12d3fb9199a",
            "312f63a6c2224f679f08ae1adad88241",
            "2981276c15eb43a2b1bc59a235f622bb",
            "94974fbc9b19403e9dd9cf5888e8a627",
            "7ebefb625f2a4d7f9a286340af7c3a15",
            "389e75b7c85d46d0b5a145da27b245aa",
            "8daf2c8589b24dad89595cb1dfc876c4",
            "a8bde308787b49a8881ec3a0ddcc5058",
            "666f5712ddb44e26b428dcc6106242c0",
            "368d29bfbf774784901f6f0352201625",
            "507444a8d1494c789f6160642bf10f29",
            "55a67ac9a7864eda8197811e5456316b",
            "88784208d1c644d68cb4ea576ae311c7",
            "a91b3f3689ec47dbb1e0f28b1a2871e8",
            "86f75dec5832404ab53ca82fb5af5176",
            "525e3711a4964948851260cbc72a0acb",
            "97b9506da0a74a6d8355979e33ea2b31",
            "d541031bf3fc43aeac6aea9eaddc44c1",
            "2394c113a0da4fe0becadaf89fdf2a0e",
            "9b118f16f20e49b199f5d0baf898d9a2",
            "cd2a9de0819b48c9b2f3306b2d4e71db",
            "dbdce226d3134eec9718f4f17dcbc00f",
            "c08d2596bda444fdbb26d3649fb40636",
            "3b05ff7334f544b4bdf2dd957260cfad",
            "219df13d0d094e70b9682efd5534f07d",
            "e3226ff6c3814512b674a4ba116254c0"
          ]
        },
        "id": "SVYHBvaMEsCd",
        "outputId": "e306a210-e976-4acc-e73c-b2ba25c811b0"
      },
      "source": [
        "\n",
        "#import neccessary modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import autogluon.core as ag\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "DataSet = pd.read_csv('csv_nfl_data.csv')\n",
        "DataSet.head()\n",
        "\n",
        "with open('csv_nfl_data.csv','r') as f:\n",
        "    data = f.read().split('\\n')\n",
        "data[1]=data[0]+data[1]\n",
        "del data[0]\n",
        "with open('changed_dataset.csv','w') as f:\n",
        "    for i in data:\n",
        "        f.write(i+'\\n')\n",
        "\n",
        "\n",
        "dataset = pd.read_csv('changed_dataset.csv')\n",
        "\n",
        "dataset.head()\n",
        "\n",
        "dataset.info()\n",
        "\n",
        "dataset.drop(\"Date(IST)\",inplace=True,axis=1)\n",
        "dataset.isnull().sum()\n",
        "\n",
        "null_list = ['FIIB','FIIS','FIIN','DIIB','DIIS','DIIN','August','December']\n",
        "for i in null_list:\n",
        "    dataset[i]=dataset[i].fillna(dataset[i].mean())\n",
        "\n",
        "dataset.isnull().sum()\n",
        "\n",
        "#with NFH and without NFL dataset \n",
        "dataset_NFH = dataset.drop('NFL',axis=1)\n",
        "#with NFL and without NFH dataset\n",
        "dataset_NFL = dataset.drop('NFH',axis=1)\n",
        "\n",
        "def Train_Test_Split(dataset):\n",
        "    train, test = train_test_split(dataset , train_size=0.7, test_size=0.3)\n",
        "    return (train,test)\n",
        "\n",
        "#NFH dataset split into train and test\n",
        "train_NFH, test_NFH = Train_Test_Split(dataset_NFH)\n",
        "#NFL dataset split into train and test\n",
        "train_NFL, test_NFL = Train_Test_Split(dataset_NFL)\n",
        "\n",
        "train_NFH.to_csv('train_NFH.csv', index=False)\n",
        "test_NFH.to_csv('test_NFH.csv',index=False)\n",
        "train_NFL.to_csv('train_NFL.csv',index=False)\n",
        "test_NFL.to_csv('test_NFL.csv',index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###########################################  NFH  ######################################\n",
        "train_data = TabularDataset('train_NFH.csv')\n",
        "subsample_size = 200  # subsample subset of data for faster demo, try setting this to much larger values\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0,replace=True)\n",
        "\n",
        "label = 'NFH'\n",
        "\n",
        "new_data = TabularDataset('test_NFH.csv')\n",
        "test_data = new_data[75:].copy()  # this should be separate data in your applications\n",
        "y_test = test_data[label]\n",
        "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
        "val_data = new_data[:75].copy()\n",
        "\n",
        "sc=MinMaxScaler\n",
        "\n",
        "\n",
        "display(train_data)\n",
        "\n",
        "display(val_data)\n",
        "\n",
        "\n",
        "metric = 'mean_squared_error' # we specify eval-metric just for demo (unnecessary as it's the default)\n",
        "\n",
        "import autogluon.core as ag\n",
        "\n",
        "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
        "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
        "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
        "    'layers': ag.space.Categorical([10], [10], [20, 10], [30, 20, 10]),  # each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n",
        "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
        "}\n",
        "\n",
        "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
        "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
        "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
        "}\n",
        "\n",
        "hyperparameters = {  # hyperparameters of each model type\n",
        "                   'GBM': gbm_options,\n",
        "                   'NN': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
        "              \n",
        "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
        "\n",
        "time_limit = 2*60  # train various models for ~2 min\n",
        "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
        "search_strategy = 'auto'  # to tune hyperparameters using Bayesian optimization routine with a local scheduler\n",
        "\n",
        "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
        "    'num_trials': num_trials,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data, tuning_data=val_data, time_limit=time_limit,\n",
        "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(test_data_nolabel)\n",
        "print(\"Predictions:  \", list(y_pred)[:5])\n",
        "perf = predictor.evaluate(test_data, auxiliary_metrics=False)\n",
        "\n",
        "results = predictor.fit_summary() #Summary\n",
        "\n",
        "\n",
        "#Model ensembling with stacking/bagging\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
        "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n",
        "    hyperparameters = {'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n",
        ")\n",
        "\n",
        "\n",
        "save_path = 'ModelFolderNFH'  # folder where to store trained models\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric, path=save_path).fit(\n",
        "    train_data, auto_stack=True,\n",
        "    time_limit=30, hyperparameters={'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}}  # last 2 arguments are for quick demo, omit them in real applications\n",
        ")\n",
        "\n",
        "\n",
        "#Prediction options (inference) NFH model\n",
        "predictor = TabularPredictor.load(save_path)\n",
        "\n",
        "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
        "print(datapoint)\n",
        "predictor.predict(datapoint)\n",
        "\n",
        "predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class\n",
        "\n",
        "predictor.get_model_best()\n",
        "\n",
        "predictor.leaderboard(test_data, silent=True)\n",
        "\n",
        "predictor.leaderboard(extra_info=True, silent=True)\n",
        "\n",
        "predictor.leaderboard(test_data, extra_metrics=['root_mean_squared_error', 'mean_squared_error', 'mean_absolute_error', 'median_absolute_error', 'r2'], silent=True)\n",
        "i = 0  # index of model to use\n",
        "model_to_use = predictor.get_model_names()[i]\n",
        "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
        "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))\n",
        "\n",
        "\n",
        "all_models = predictor.get_model_names()\n",
        "model_to_use = all_models[i]\n",
        "specific_model = predictor._trainer.load_model(model_to_use)\n",
        "\n",
        "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
        "model_info = specific_model.get_info()\n",
        "predictor_information = predictor.info()\n",
        "\n",
        "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
        "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)\n",
        "\n",
        "perf = predictor.evaluate(test_data)\n",
        "\n",
        "predictor.feature_importance(test_data)\n",
        "\n",
        "predictor.persist_models()\n",
        "\n",
        "num_test = 20\n",
        "preds = np.array(['']*num_test, dtype='object')\n",
        "for i in range(num_test):\n",
        "    datapoint = test_data_nolabel.iloc[[i]]\n",
        "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
        "    preds[i] = pred_numpy[0]\n",
        "\n",
        "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
        "print(\"Predictions: \", preds)\n",
        "\n",
        "predictor.unpersist_models()\n",
        "\n",
        "#Using smaller ensemble or faster model for prediction\n",
        "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
        "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
        "\n",
        "predictor.leaderboard(only_pareto_frontier=True, silent=True)\n",
        "model_for_prediction = additional_ensembles[0]\n",
        "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
        "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial\n",
        "\n",
        "#Collapsing bagged ensembles via refit_full\n",
        "refit_model_map = predictor.refit_full()\n",
        "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
        "print(refit_model_map)\n",
        "predictor.leaderboard(test_data, silent=True)\n",
        "\n",
        "#ModelDistilation\n",
        "student_models = predictor.distill(time_limit=30)  # specify much longer time limit in real applications\n",
        "print(student_models)\n",
        "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
        "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
        "predictor.leaderboard(test_data)\n",
        "\n",
        "#Faster presets or hyperparameters\n",
        "presets = ['good_quality_faster_inference_only_refit', 'optimize_for_deployment']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)\n",
        "\n",
        "excluded_model_types = ['KNN', 'NN', 'custom']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########################################   NFL   ########################################\n",
        "train_data = TabularDataset('train_NFL.csv')\n",
        "subsample_size = 200  # subsample subset of data for faster demo, try setting this to much larger values\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0,replace=True)\n",
        "\n",
        "label = 'NFL'\n",
        "\n",
        "new_data = TabularDataset('test_NFL.csv')\n",
        "test_data = new_data[75:].copy()  # this should be separate data in your applications\n",
        "y_test = test_data[label]\n",
        "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
        "val_data = new_data[:75].copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "display(train_data)\n",
        "\n",
        "display(val_data)\n",
        "\n",
        "\n",
        "metric = 'mean_squared_error' # we specify eval-metric just for demo (unnecessary as it's the default)\n",
        "\n",
        "import autogluon.core as ag\n",
        "\n",
        "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
        "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
        "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
        "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
        "    'layers': ag.space.Categorical([10], [10], [20, 10], [30, 20, 10]),  # each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n",
        "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
        "}\n",
        "\n",
        "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
        "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
        "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
        "}\n",
        "\n",
        "hyperparameters = {  # hyperparameters of each model type\n",
        "                   'GBM': gbm_options,\n",
        "                   'NN': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
        "              \n",
        "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
        "\n",
        "time_limit = 2*60  # train various models for ~2 min\n",
        "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
        "search_strategy = 'auto'  # to tune hyperparameters using Bayesian optimization routine with a local scheduler\n",
        "\n",
        "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
        "    'num_trials': num_trials,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data, tuning_data=val_data, time_limit=time_limit,\n",
        "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(test_data_nolabel)\n",
        "print(\"Predictions:  \", list(y_pred)[:5])\n",
        "perf = predictor.evaluate(test_data, auxiliary_metrics=False)\n",
        "\n",
        "results = predictor.fit_summary() #Summary\n",
        "\n",
        "\n",
        "#Model ensembling with stacking/bagging\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
        "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n",
        "    hyperparameters = {'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n",
        ")\n",
        "\n",
        "\n",
        "save_path = 'ModelFolderNFL'  # folder where to store trained models\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric, path=save_path).fit(\n",
        "    train_data, auto_stack=True,\n",
        "    time_limit=30, hyperparameters={'NN': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}}  # last 2 arguments are for quick demo, omit them in real applications\n",
        ")\n",
        "\n",
        "\n",
        "#Prediction options (inference) NFH model\n",
        "predictor = TabularPredictor.load(save_path)\n",
        "\n",
        "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
        "print(datapoint)\n",
        "predictor.predict(datapoint)\n",
        "\n",
        "predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class\n",
        "\n",
        "predictor.get_model_best()\n",
        "\n",
        "predictor.leaderboard(test_data, silent=True)\n",
        "\n",
        "predictor.leaderboard(extra_info=True, silent=True)\n",
        "\n",
        "predictor.leaderboard(test_data, extra_metrics=['root_mean_squared_error', 'mean_squared_error', 'mean_absolute_error', 'median_absolute_error', 'r2'], silent=True)\n",
        "i = 0  # index of model to use\n",
        "model_to_use = predictor.get_model_names()[i]\n",
        "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
        "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))\n",
        "\n",
        "\n",
        "all_models = predictor.get_model_names()\n",
        "model_to_use = all_models[i]\n",
        "specific_model = predictor._trainer.load_model(model_to_use)\n",
        "\n",
        "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
        "model_info = specific_model.get_info()\n",
        "predictor_information = predictor.info()\n",
        "\n",
        "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
        "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)\n",
        "\n",
        "perf = predictor.evaluate(test_data)\n",
        "\n",
        "predictor.feature_importance(test_data)\n",
        "\n",
        "predictor.persist_models()\n",
        "\n",
        "num_test = 20\n",
        "preds = np.array(['']*num_test, dtype='object')\n",
        "for i in range(num_test):\n",
        "    datapoint = test_data_nolabel.iloc[[i]]\n",
        "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
        "    preds[i] = pred_numpy[0]\n",
        "\n",
        "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
        "print(\"Predictions: \", preds)\n",
        "\n",
        "predictor.unpersist_models()\n",
        "\n",
        "#Using smaller ensemble or faster model for prediction\n",
        "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
        "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
        "\n",
        "predictor.leaderboard(only_pareto_frontier=True, silent=True)\n",
        "model_for_prediction = additional_ensembles[0]\n",
        "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
        "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial\n",
        "\n",
        "#Collapsing bagged ensembles via refit_full\n",
        "refit_model_map = predictor.refit_full()\n",
        "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
        "print(refit_model_map)\n",
        "predictor.leaderboard(test_data, silent=True)\n",
        "\n",
        "#ModelDistillation\n",
        "student_models = predictor.distill(time_limit=30)  # specify much longer time limit in real applications\n",
        "print(student_models)\n",
        "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
        "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
        "predictor.leaderboard(test_data)\n",
        "\n",
        "#Faster presets or hyperparameters\n",
        "presets = ['good_quality_faster_inference_only_refit', 'optimize_for_deployment']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)\n",
        "\n",
        "excluded_model_types = ['KNN', 'NN', 'custom']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 358 entries, 0 to 357\n",
            "Data columns (total 22 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   nfl_data   358 non-null    int64  \n",
            " 1   Date(IST)  358 non-null    object \n",
            " 2   NFO        358 non-null    float64\n",
            " 3   NFH        358 non-null    float64\n",
            " 4   NFL        358 non-null    float64\n",
            " 5   NFC        358 non-null    float64\n",
            " 6   FIIB       357 non-null    float64\n",
            " 7   FIIS       357 non-null    float64\n",
            " 8   FIIN       357 non-null    float64\n",
            " 9   DIIB       357 non-null    float64\n",
            " 10  DIIS       357 non-null    float64\n",
            " 11  DIIN       357 non-null    float64\n",
            " 12  August     356 non-null    float64\n",
            " 13  December   356 non-null    float64\n",
            " 14  CAD        358 non-null    float64\n",
            " 15  DAD        358 non-null    float64\n",
            " 16  DOD        358 non-null    float64\n",
            " 17  NDAD       358 non-null    float64\n",
            " 18  Currey     358 non-null    float64\n",
            " 19  Flow       358 non-null    float64\n",
            " 20  Shine      358 non-null    float64\n",
            " 21  Vega       358 non-null    float64\n",
            "dtypes: float64(20), int64(1), object(1)\n",
            "memory usage: 61.7+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfl_data</th>\n",
              "      <th>NFO</th>\n",
              "      <th>NFH</th>\n",
              "      <th>NFC</th>\n",
              "      <th>FIIB</th>\n",
              "      <th>FIIS</th>\n",
              "      <th>FIIN</th>\n",
              "      <th>DIIB</th>\n",
              "      <th>DIIS</th>\n",
              "      <th>DIIN</th>\n",
              "      <th>August</th>\n",
              "      <th>December</th>\n",
              "      <th>CAD</th>\n",
              "      <th>DAD</th>\n",
              "      <th>DOD</th>\n",
              "      <th>NDAD</th>\n",
              "      <th>Currey</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Shine</th>\n",
              "      <th>Vega</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>29</td>\n",
              "      <td>12131.397886</td>\n",
              "      <td>12165.472693</td>\n",
              "      <td>12100.911068</td>\n",
              "      <td>5071.12</td>\n",
              "      <td>5022.31</td>\n",
              "      <td>48.81</td>\n",
              "      <td>3795.48</td>\n",
              "      <td>3456.29</td>\n",
              "      <td>339.19</td>\n",
              "      <td>722.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.59</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>0.0845</td>\n",
              "      <td>0.4492</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-1.440001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>90</td>\n",
              "      <td>8868.805879</td>\n",
              "      <td>9024.544308</td>\n",
              "      <td>8939.041940</td>\n",
              "      <td>6102.70</td>\n",
              "      <td>6361.43</td>\n",
              "      <td>-258.73</td>\n",
              "      <td>3602.92</td>\n",
              "      <td>3201.14</td>\n",
              "      <td>401.78</td>\n",
              "      <td>1049.0</td>\n",
              "      <td>721.0</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.3360</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>1.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>12</td>\n",
              "      <td>12392.260613</td>\n",
              "      <td>12418.086057</td>\n",
              "      <td>12390.792053</td>\n",
              "      <td>6609.58</td>\n",
              "      <td>6345.32</td>\n",
              "      <td>264.26</td>\n",
              "      <td>3615.43</td>\n",
              "      <td>4115.60</td>\n",
              "      <td>-500.17</td>\n",
              "      <td>946.0</td>\n",
              "      <td>886.0</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.1400</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.1145</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.219999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>120</td>\n",
              "      <td>10477.183228</td>\n",
              "      <td>10574.081442</td>\n",
              "      <td>10540.191523</td>\n",
              "      <td>4111.43</td>\n",
              "      <td>3763.08</td>\n",
              "      <td>348.35</td>\n",
              "      <td>4205.92</td>\n",
              "      <td>3942.45</td>\n",
              "      <td>263.47</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>771.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.02</td>\n",
              "      <td>-0.1790</td>\n",
              "      <td>0.1416</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>310</td>\n",
              "      <td>14425.143888</td>\n",
              "      <td>14448.520143</td>\n",
              "      <td>14288.410144</td>\n",
              "      <td>9619.52</td>\n",
              "      <td>10529.08</td>\n",
              "      <td>-909.56</td>\n",
              "      <td>5737.09</td>\n",
              "      <td>4887.11</td>\n",
              "      <td>849.98</td>\n",
              "      <td>1136.0</td>\n",
              "      <td>782.0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>-1.55</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.3100</td>\n",
              "      <td>-0.2600</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.029999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>273</td>\n",
              "      <td>15198.939630</td>\n",
              "      <td>15237.382613</td>\n",
              "      <td>15077.552219</td>\n",
              "      <td>9454.13</td>\n",
              "      <td>10347.38</td>\n",
              "      <td>-893.25</td>\n",
              "      <td>4804.05</td>\n",
              "      <td>5723.93</td>\n",
              "      <td>-919.88</td>\n",
              "      <td>569.0</td>\n",
              "      <td>1395.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>-0.0490</td>\n",
              "      <td>2.09</td>\n",
              "      <td>-2.81</td>\n",
              "      <td>-0.0295</td>\n",
              "      <td>0.6418</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.400002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>344</td>\n",
              "      <td>15821.507577</td>\n",
              "      <td>15862.941950</td>\n",
              "      <td>15819.850213</td>\n",
              "      <td>4339.27</td>\n",
              "      <td>4842.78</td>\n",
              "      <td>-503.51</td>\n",
              "      <td>4801.07</td>\n",
              "      <td>4256.81</td>\n",
              "      <td>544.26</td>\n",
              "      <td>899.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>-1.04</td>\n",
              "      <td>2.21</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>173</td>\n",
              "      <td>11595.460247</td>\n",
              "      <td>11609.162107</td>\n",
              "      <td>11538.238776</td>\n",
              "      <td>5230.50</td>\n",
              "      <td>5770.31</td>\n",
              "      <td>-539.81</td>\n",
              "      <td>4333.23</td>\n",
              "      <td>4851.18</td>\n",
              "      <td>-517.95</td>\n",
              "      <td>294.0</td>\n",
              "      <td>1639.0</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>-1.3015</td>\n",
              "      <td>-2.46</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>-0.3487</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>1.950001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>249</td>\n",
              "      <td>14689.155319</td>\n",
              "      <td>14730.963589</td>\n",
              "      <td>14666.101429</td>\n",
              "      <td>10175.47</td>\n",
              "      <td>9098.85</td>\n",
              "      <td>1076.62</td>\n",
              "      <td>5772.80</td>\n",
              "      <td>5960.90</td>\n",
              "      <td>-188.10</td>\n",
              "      <td>912.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0968</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>0.0505</td>\n",
              "      <td>0.1800</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.040001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>266</td>\n",
              "      <td>15285.955321</td>\n",
              "      <td>15362.443064</td>\n",
              "      <td>15261.359360</td>\n",
              "      <td>9072.10</td>\n",
              "      <td>7285.13</td>\n",
              "      <td>1786.97</td>\n",
              "      <td>4749.91</td>\n",
              "      <td>6825.59</td>\n",
              "      <td>-2075.68</td>\n",
              "      <td>879.0</td>\n",
              "      <td>1048.0</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.0734</td>\n",
              "      <td>1.07</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-0.0180</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.360001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     nfl_data           NFO           NFH  ...    Flow  Shine      Vega\n",
              "172        29  12131.397886  12165.472693  ...  0.4492  -0.03 -1.440001\n",
              "47         90   8868.805879   9024.544308  ...  0.1793  -0.99  1.540001\n",
              "117        12  12392.260613  12418.086057  ...  0.0681  -0.14 -0.219999\n",
              "192       120  10477.183228  10574.081442  ...  0.1416   0.34  0.260000\n",
              "67        310  14425.143888  14448.520143  ... -0.2600   0.01  0.029999\n",
              "..        ...           ...           ...  ...     ...    ...       ...\n",
              "30        273  15198.939630  15237.382613  ...  0.6418   0.75  1.400002\n",
              "24        344  15821.507577  15862.941950  ...  0.0700  -0.08  0.740000\n",
              "125       173  11595.460247  11609.162107  ... -0.3487  -0.70  1.950001\n",
              "2         249  14689.155319  14730.963589  ...  0.1800   0.08  1.040001\n",
              "3         266  15285.955321  15362.443064  ...  0.0700   0.08  0.360001\n",
              "\n",
              "[200 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfl_data</th>\n",
              "      <th>NFO</th>\n",
              "      <th>NFH</th>\n",
              "      <th>NFC</th>\n",
              "      <th>FIIB</th>\n",
              "      <th>FIIS</th>\n",
              "      <th>FIIN</th>\n",
              "      <th>DIIB</th>\n",
              "      <th>DIIS</th>\n",
              "      <th>DIIN</th>\n",
              "      <th>August</th>\n",
              "      <th>December</th>\n",
              "      <th>CAD</th>\n",
              "      <th>DAD</th>\n",
              "      <th>DOD</th>\n",
              "      <th>NDAD</th>\n",
              "      <th>Currey</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Shine</th>\n",
              "      <th>Vega</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170</td>\n",
              "      <td>11503.579133</td>\n",
              "      <td>11544.444268</td>\n",
              "      <td>11501.759339</td>\n",
              "      <td>4980.880000</td>\n",
              "      <td>4716.220000</td>\n",
              "      <td>264.660000</td>\n",
              "      <td>4259.670000</td>\n",
              "      <td>4471.880000</td>\n",
              "      <td>-212.210000</td>\n",
              "      <td>966.0</td>\n",
              "      <td>864.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>-1.37</td>\n",
              "      <td>-0.86</td>\n",
              "      <td>-0.0580</td>\n",
              "      <td>0.4786</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.450001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107</td>\n",
              "      <td>9837.276863</td>\n",
              "      <td>9983.324733</td>\n",
              "      <td>9873.176784</td>\n",
              "      <td>4608.090000</td>\n",
              "      <td>6086.610000</td>\n",
              "      <td>-1478.520000</td>\n",
              "      <td>4742.480000</td>\n",
              "      <td>3580.970000</td>\n",
              "      <td>1161.510000</td>\n",
              "      <td>847.0</td>\n",
              "      <td>1036.0</td>\n",
              "      <td>1.26</td>\n",
              "      <td>0.4890</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.2560</td>\n",
              "      <td>0.2257</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-0.730003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300</td>\n",
              "      <td>14773.489712</td>\n",
              "      <td>14852.499486</td>\n",
              "      <td>14823.579735</td>\n",
              "      <td>4825.290000</td>\n",
              "      <td>5918.040000</td>\n",
              "      <td>-1092.750000</td>\n",
              "      <td>4518.840000</td>\n",
              "      <td>4102.250000</td>\n",
              "      <td>416.590000</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.4611</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.81</td>\n",
              "      <td>0.1730</td>\n",
              "      <td>-0.4400</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.790001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134</td>\n",
              "      <td>11244.893725</td>\n",
              "      <td>11316.991796</td>\n",
              "      <td>11280.792472</td>\n",
              "      <td>7666.212493</td>\n",
              "      <td>7402.904678</td>\n",
              "      <td>263.307731</td>\n",
              "      <td>4715.688011</td>\n",
              "      <td>4785.561345</td>\n",
              "      <td>-69.873193</td>\n",
              "      <td>684.0</td>\n",
              "      <td>1190.0</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.2050</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.0514</td>\n",
              "      <td>0.0119</td>\n",
              "      <td>0.45</td>\n",
              "      <td>-0.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>221</td>\n",
              "      <td>13124.071523</td>\n",
              "      <td>13168.988803</td>\n",
              "      <td>13108.175126</td>\n",
              "      <td>9295.460000</td>\n",
              "      <td>8938.110000</td>\n",
              "      <td>357.350000</td>\n",
              "      <td>3377.190000</td>\n",
              "      <td>5013.160000</td>\n",
              "      <td>-1635.970000</td>\n",
              "      <td>1096.0</td>\n",
              "      <td>796.0</td>\n",
              "      <td>0.64</td>\n",
              "      <td>-0.0250</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>0.2151</td>\n",
              "      <td>0.1487</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>289</td>\n",
              "      <td>15065.660637</td>\n",
              "      <td>15083.937729</td>\n",
              "      <td>14927.645682</td>\n",
              "      <td>9973.210000</td>\n",
              "      <td>7347.390000</td>\n",
              "      <td>2625.820000</td>\n",
              "      <td>5874.440000</td>\n",
              "      <td>6436.590000</td>\n",
              "      <td>-562.150000</td>\n",
              "      <td>382.0</td>\n",
              "      <td>1582.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.3800</td>\n",
              "      <td>2.83</td>\n",
              "      <td>-1.45</td>\n",
              "      <td>0.0380</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>0.42</td>\n",
              "      <td>-0.560001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>350</td>\n",
              "      <td>15589.111367</td>\n",
              "      <td>15770.988848</td>\n",
              "      <td>15728.427733</td>\n",
              "      <td>6488.060000</td>\n",
              "      <td>7516.000000</td>\n",
              "      <td>-1027.940000</td>\n",
              "      <td>5099.010000</td>\n",
              "      <td>4796.560000</td>\n",
              "      <td>302.450000</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>792.0</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>0.39</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>0.0650</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-1.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>320</td>\n",
              "      <td>14683.806797</td>\n",
              "      <td>14732.337352</td>\n",
              "      <td>14691.893652</td>\n",
              "      <td>7159.990000</td>\n",
              "      <td>8302.740000</td>\n",
              "      <td>-1142.750000</td>\n",
              "      <td>6414.230000</td>\n",
              "      <td>4946.140000</td>\n",
              "      <td>1468.090000</td>\n",
              "      <td>1097.0</td>\n",
              "      <td>834.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.6434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.98</td>\n",
              "      <td>-0.3480</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>0.37</td>\n",
              "      <td>-1.699999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>349</td>\n",
              "      <td>15751.096068</td>\n",
              "      <td>15790.801125</td>\n",
              "      <td>15704.512166</td>\n",
              "      <td>4675.480000</td>\n",
              "      <td>5920.190000</td>\n",
              "      <td>-1244.710000</td>\n",
              "      <td>4028.310000</td>\n",
              "      <td>3890.220000</td>\n",
              "      <td>138.090000</td>\n",
              "      <td>1255.0</td>\n",
              "      <td>770.0</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>1.13</td>\n",
              "      <td>2.98</td>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.40</td>\n",
              "      <td>-2.810001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>142</td>\n",
              "      <td>10987.745773</td>\n",
              "      <td>11095.826688</td>\n",
              "      <td>11025.953066</td>\n",
              "      <td>5976.570000</td>\n",
              "      <td>6036.750000</td>\n",
              "      <td>-60.180000</td>\n",
              "      <td>3055.350000</td>\n",
              "      <td>3481.330000</td>\n",
              "      <td>-425.980000</td>\n",
              "      <td>1192.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.66</td>\n",
              "      <td>-0.2600</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.770000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    nfl_data           NFO           NFH  ...    Flow  Shine      Vega\n",
              "0        170  11503.579133  11544.444268  ...  0.4786   0.00  0.450001\n",
              "1        107   9837.276863   9983.324733  ...  0.2257  -0.36 -0.730003\n",
              "2        300  14773.489712  14852.499486  ... -0.4400   0.51  0.790001\n",
              "3        134  11244.893725  11316.991796  ...  0.0119   0.45 -0.240000\n",
              "4        221  13124.071523  13168.988803  ...  0.1487   0.13  0.400000\n",
              "..       ...           ...           ...  ...     ...    ...       ...\n",
              "70       289  15065.660637  15083.937729  ... -0.0600   0.42 -0.560001\n",
              "71       350  15589.111367  15770.988848  ...  0.0650  -0.07 -1.230000\n",
              "72       320  14683.806797  14732.337352  ... -0.0190   0.37 -1.699999\n",
              "73       349  15751.096068  15790.801125  ...  0.3700   0.40 -2.810001\n",
              "74       142  10987.745773  11095.826688  ...  0.2000   0.09 -0.770000\n",
              "\n",
              "[75 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_083722/\"\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_083722/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Tuning Data Rows:    75\n",
            "Tuning Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12719.08 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Hyperparameter tuning model: LightGBM ...\n",
            "NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f856b1e61de4953912081d2bdd5af83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fitted model: LightGBM/T0 ...\n",
            "\t-27403.7762\t = Validation mean_squared_error score\n",
            "\t0.17s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T1 ...\n",
            "\t-54939.3074\t = Validation mean_squared_error score\n",
            "\t0.16s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T2 ...\n",
            "\t-27279.7499\t = Validation mean_squared_error score\n",
            "\t0.22s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T3 ...\n",
            "\t-93986.651\t = Validation mean_squared_error score\n",
            "\t0.21s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T4 ...\n",
            "\t-33199.9534\t = Validation mean_squared_error score\n",
            "\t0.18s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2981276c15eb43a2b1bc59a235f622bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetMXNet/T0 ...\n",
            "\t-3916643.5\t = Validation mean_squared_error score\n",
            "\t0.28s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T1 ...\n",
            "\t-4139304.5\t = Validation mean_squared_error score\n",
            "\t0.28s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T2 ...\n",
            "\t-3956607.25\t = Validation mean_squared_error score\n",
            "\t0.24s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T3 ...\n",
            "\t-4070151.75\t = Validation mean_squared_error score\n",
            "\t0.27s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T4 ...\n",
            "\t-3942460.5\t = Validation mean_squared_error score\n",
            "\t0.26s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.88s of the 111.44s of remaining time.\n",
            "\t-21378.239\t = Validation mean_squared_error score\n",
            "\t0.36s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.94s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_083722/\")\n",
            "Evaluation: mean_squared_error on test data: -23083.14622946835\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -23083.14622946835\n",
            "}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictions:   [10583.3916015625, 15399.162109375, 9066.73828125, 12201.740234375, 15607.7529296875]\n",
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model     score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2 -2.137824e+04       0.010351  0.930650                0.000646           0.355164            2       True         11\n",
            "1           LightGBM/T2 -2.727975e+04       0.003138  0.222765                0.003138           0.222765            1       True          3\n",
            "2           LightGBM/T0 -2.740378e+04       0.003505  0.168015                0.003505           0.168015            1       True          1\n",
            "3           LightGBM/T4 -3.319995e+04       0.003063  0.184706                0.003063           0.184706            1       True          5\n",
            "4           LightGBM/T1 -5.493931e+04       0.003075  0.162587                0.003075           0.162587            1       True          2\n",
            "5           LightGBM/T3 -9.398665e+04       0.003743  0.214040                0.003743           0.214040            1       True          4\n",
            "6     NeuralNetMXNet/T0 -3.916644e+06       0.003690  0.281994                0.003690           0.281994            1       True          6\n",
            "7     NeuralNetMXNet/T4 -3.942460e+06       0.003430  0.255941                0.003430           0.255941            1       True         10\n",
            "8     NeuralNetMXNet/T2 -3.956607e+06       0.003351  0.236578                0.003351           0.236578            1       True          8\n",
            "9     NeuralNetMXNet/T3 -4.070152e+06       0.003580  0.271954                0.003580           0.271954            1       True          9\n",
            "10    NeuralNetMXNet/T1 -4.139304e+06       0.003374  0.276299                0.003374           0.276299            1       True          7\n",
            "Number of models trained: 11\n",
            "Types of models trained:\n",
            "{'LGBModel', 'TabularNeuralNetModel', 'WeightedEnsembleModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "('int', [])   :  1 | ['nfl_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_083731/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_083731/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12672.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Plot summary of models saved to file: AutogluonModels/ag-20210715_083722/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\t-644328.4741\t = Validation mean_squared_error score\n",
            "\t0.76s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
            "\t-4354977.3867\t = Validation mean_squared_error score\n",
            "\t2.05s\t = Training runtime\n",
            "\t0.75s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-644328.4741\t = Validation mean_squared_error score\n",
            "\t0.09s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\t-630892.0031\t = Validation mean_squared_error score\n",
            "\t0.76s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
            "\t-4398439.1041\t = Validation mean_squared_error score\n",
            "\t2.05s\t = Training runtime\n",
            "\t0.76s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\t-630892.0031\t = Validation mean_squared_error score\n",
            "\t0.09s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.64s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_083731/\")\n",
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ModelFolderNFH\"\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"ModelFolderNFH/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12672.07 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.89s of the 29.89s of remaining time.\n",
            "\t-644328.4741\t = Validation mean_squared_error score\n",
            "\t0.8s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 29.06s of the 29.06s of remaining time.\n",
            "\t-4531410.2763\t = Validation mean_squared_error score\n",
            "\t2.03s\t = Training runtime\n",
            "\t0.75s\t = Validation runtime\n",
            "Repeating k-fold bagging: 2/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 26.25s of the 26.24s of remaining time.\n",
            "\t-649481.6721\t = Validation mean_squared_error score\n",
            "\t1.55s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 25.46s of the 25.46s of remaining time.\n",
            "\t-4388790.5412\t = Validation mean_squared_error score\n",
            "\t4.02s\t = Training runtime\n",
            "\t1.54s\t = Validation runtime\n",
            "Repeating k-fold bagging: 3/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 22.6s of the 22.6s of remaining time.\n",
            "\t-646598.0652\t = Validation mean_squared_error score\n",
            "\t2.32s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 21.79s of the 21.79s of remaining time.\n",
            "\t-4385683.6887\t = Validation mean_squared_error score\n",
            "\t6.07s\t = Training runtime\n",
            "\t2.3s\t = Validation runtime\n",
            "Repeating k-fold bagging: 4/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 18.95s of the 18.94s of remaining time.\n",
            "\t-643575.3683\t = Validation mean_squared_error score\n",
            "\t3.09s\t = Training runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 18.13s of the 18.13s of remaining time.\n",
            "\t-4312710.3852\t = Validation mean_squared_error score\n",
            "\t8.11s\t = Training runtime\n",
            "\t3.06s\t = Validation runtime\n",
            "Repeating k-fold bagging: 5/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.29s of the 15.28s of remaining time.\n",
            "\t-643442.1795\t = Validation mean_squared_error score\n",
            "\t3.85s\t = Training runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 14.49s of the 14.49s of remaining time.\n",
            "\t-4361228.338\t = Validation mean_squared_error score\n",
            "\t10.17s\t = Training runtime\n",
            "\t3.82s\t = Validation runtime\n",
            "Repeating k-fold bagging: 6/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 11.62s of the 11.62s of remaining time.\n",
            "\t-643170.8371\t = Validation mean_squared_error score\n",
            "\t4.61s\t = Training runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 10.83s of the 10.83s of remaining time.\n",
            "\t-4354602.0271\t = Validation mean_squared_error score\n",
            "\t12.22s\t = Training runtime\n",
            "\t4.58s\t = Validation runtime\n",
            "Repeating k-fold bagging: 7/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 7.97s of the 7.97s of remaining time.\n",
            "\t-642419.0565\t = Validation mean_squared_error score\n",
            "\t5.37s\t = Training runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 7.17s of the 7.17s of remaining time.\n",
            "\t-4361625.6343\t = Validation mean_squared_error score\n",
            "\t14.24s\t = Training runtime\n",
            "\t5.36s\t = Validation runtime\n",
            "Completed 7/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.89s of the 4.33s of remaining time.\n",
            "\t-642419.0565\t = Validation mean_squared_error score\n",
            "\t0.09s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 25.78s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ModelFolderNFH/\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    nfl_data          NFO          NFC  ...    Flow  Shine      Vega\n",
            "75       114  10553.74777  10431.58257  ...  0.3943   0.02 -1.619999\n",
            "\n",
            "[1 rows x 19 columns]\n",
            "Prediction from LightGBM_BAG_L1 model: 11164.724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation: mean_squared_error on test data: -844024.7281520873\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -844024.7281520873,\n",
            "    \"root_mean_squared_error\": -918.708184437304,\n",
            "    \"mean_absolute_error\": -769.6710481046023,\n",
            "    \"r2\": 0.8498148963581438,\n",
            "    \"pearsonr\": 0.9945600912831354,\n",
            "    \"median_absolute_error\": -797.4806400864\n",
            "}\n",
            "Evaluation: mean_squared_error on test data: -844024.7281520873\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -844024.7281520873,\n",
            "    \"root_mean_squared_error\": -918.708184437304,\n",
            "    \"mean_absolute_error\": -769.6710481046023,\n",
            "    \"r2\": 0.8498148963581438,\n",
            "    \"pearsonr\": 0.9945600912831354,\n",
            "    \"median_absolute_error\": -797.4806400864\n",
            "}\n",
            "Computing feature importance via permutation shuffling for 19 features using 33 rows with 3 shuffle sets...\n",
            "\t6.66s\t= Expected runtime (2.22s per shuffle set)\n",
            "\t0.56s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n",
            "Persisting 2 models in memory. Models will require 0.01% of memory.\n",
            "Evaluation: mean_squared_error on test data: -913124.3806987794\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -913124.3806987794,\n",
            "    \"root_mean_squared_error\": NaN,\n",
            "    \"mean_absolute_error\": -838.5033385558509,\n",
            "    \"r2\": 0.8508553870935187,\n",
            "    \"pearsonr\": 0.9952544818303246,\n",
            "    \"median_absolute_error\": -873.5248735634113\n",
            "}\n",
            "Unpersisted 2 models: ['WeightedEnsemble_L2', 'LightGBM_BAG_L1']\n",
            "Fitting model: WeightedEnsemble_L2Best ...\n",
            "\t-642419.0565\t = Validation mean_squared_error score\n",
            "\t0.1s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictions:  [11164.724 14299.061 10324.453 12282.213 14298.475 10326.527 14288.327\n",
            " 11464.054 13666.842 10326.527 13677.035 11564.616 13971.469 13974.662\n",
            " 14298.475 10864.286 12223.041 10324.453 13405.546 13780.109]\n",
            "Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting model WeightedEnsemble_L2Best. All files under ModelFolderNFH/models/WeightedEnsemble_L2Best/ will be removed.\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.15s\t = Training runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1_FULL ...\n",
            "\t0.25s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL ...\n",
            "\t-642419.0565\t = Validation mean_squared_error score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Name of each refit-full model corresponding to a previous bagged ensemble:\n",
            "{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'NeuralNetMXNet_BAG_L1': 'NeuralNetMXNet_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Distilling with teacher='WeightedEnsemble_L2', teacher_preds=soft, augment_method=spunge ...\n",
            "SPUNGE: Augmenting training data with 800 synthetic samples for distillation...\n",
            "Distilling with each of these student models: ['LightGBM_DSTL', 'NeuralNetMXNet_DSTL', 'CatBoost_DSTL', 'RandomForest_DSTL']\n",
            "Fitting model: LightGBM_DSTL ... Training model for up to 30.0s of the 29.99s of remaining time.\n",
            "\t-413436.4303\t = Validation mean_squared_error score\n",
            "\t0.55s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_DSTL ... Training model for up to 29.43s of the 29.42s of remaining time.\n",
            "\t-404556.8296\t = Validation mean_squared_error score\n",
            "\t8.57s\t = Training runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost_DSTL ... Training model for up to 20.69s of the 20.68s of remaining time.\n",
            "\t-536199.0055\t = Validation mean_squared_error score\n",
            "\t1.93s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForest_DSTL ... Training model for up to 18.75s of the 18.74s of remaining time.\n",
            "\t-283286.2208\t = Validation mean_squared_error score\n",
            "\t1.86s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
            "Fitting model: WeightedEnsemble_L2_DSTL ... Training model for up to 30.0s of the 16.38s of remaining time.\n",
            "\t-283286.2208\t = Validation mean_squared_error score\n",
            "\t0.15s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Distilled model leaderboard:\n",
            "                      model      score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0         RandomForest_DSTL -283286.220778       0.103617  1.857065                0.103617           1.857065            1       True         10\n",
            "1  WeightedEnsemble_L2_DSTL -283286.220778       0.104355  2.009387                0.000738           0.152322            2       True         11\n",
            "2       NeuralNetMXNet_DSTL -404556.829614       0.159735  8.569795                0.159735           8.569795            1       True          8\n",
            "3             LightGBM_DSTL -413436.430269       0.003701  0.545862                0.003701           0.545862            1       True          7\n",
            "4             CatBoost_DSTL -536199.005532       0.002440  1.929615                0.002440           1.929615            1       True          9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['LightGBM_DSTL', 'NeuralNetMXNet_DSTL', 'CatBoost_DSTL', 'RandomForest_DSTL', 'WeightedEnsemble_L2_DSTL']\n",
            "predictions from LightGBM_DSTL: [11088.09375, 14414.818359375, 10176.71875, 12294.2568359375, 14452.3916015625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_083920/\"\n",
            "Presets specified: ['good_quality_faster_inference_only_refit', 'optimize_for_deployment']\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_083920/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12644.0 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 29.9s of the 29.9s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                         model    score_test     score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0            RandomForest_DSTL -6.331327e+05 -2.832862e+05        0.127127       0.103617   1.857065                 0.127127                0.103617           1.857065            1       True         10\n",
            "1     WeightedEnsemble_L2_DSTL -6.331327e+05 -2.832862e+05        0.129231       0.104355   2.009387                 0.002104                0.000738           0.152322            2       True         11\n",
            "2                LightGBM_DSTL -6.817221e+05 -4.134364e+05        0.006579       0.003701   0.545862                 0.006579                0.003701           0.545862            1       True          7\n",
            "3                CatBoost_DSTL -7.233715e+05 -5.361990e+05        0.003031       0.002440   1.929615                 0.003031                0.002440           1.929615            1       True          9\n",
            "4         LightGBM_BAG_L1_FULL -7.981241e+05           NaN        0.002650            NaN   0.147694                 0.002650                     NaN           0.147694            1       True          4\n",
            "5     WeightedEnsemble_L2_FULL -7.981241e+05           NaN        0.004445            NaN   0.150811                 0.001795                0.000947           0.003117            2       True          6\n",
            "6          NeuralNetMXNet_DSTL -8.432150e+05 -4.045568e+05        0.161006       0.159735   8.569795                 0.161006                0.159735           8.569795            1       True          8\n",
            "7              LightGBM_BAG_L1 -8.440247e+05 -6.424191e+05        0.099986       0.082005   5.372597                 0.099986                0.082005           5.372597            1       True          1\n",
            "8          WeightedEnsemble_L2 -8.440247e+05 -6.424191e+05        0.105931       0.082580   5.466706                 0.005945                0.000575           0.094109            2       True          3\n",
            "9        NeuralNetMXNet_BAG_L1 -5.694551e+06 -4.361626e+06        5.827932       5.358778  14.238779                 5.827932                5.358778          14.238779            1       True          2\n",
            "10  NeuralNetMXNet_BAG_L1_FULL -6.072373e+06           NaN        0.168733            NaN   0.246290                 0.168733                     NaN           0.246290            1       True          5\n",
            "[1000]\ttrain_set's l2: 1669.45\tvalid_set's l2: 68992.8\n",
            "[2000]\ttrain_set's l2: 200.36\tvalid_set's l2: 67328.8\n",
            "[3000]\ttrain_set's l2: 34.0636\tvalid_set's l2: 67017.8\n",
            "[1000]\ttrain_set's l2: 1682.16\tvalid_set's l2: 62394.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-42445.5158\t = Validation mean_squared_error score\n",
            "\t2.05s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 27.81s of the 27.8s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 2306.86\tvalid_set's l2: 32155.1\n",
            "[1000]\ttrain_set's l2: 365.437\tvalid_set's l2: 41818.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-23191.0016\t = Validation mean_squared_error score\n",
            "\t1.37s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 26.39s of the 26.39s of remaining time.\n",
            "\t-4805.6461\t = Validation mean_squared_error score\n",
            "\t0.83s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 25.43s of the 25.43s of remaining time.\n",
            "\t-61340.3942\t = Validation mean_squared_error score\n",
            "\t9.19s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 16.2s of the 16.2s of remaining time.\n",
            "\t-4187.5242\t = Validation mean_squared_error score\n",
            "\t0.64s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 15.45s of the 15.45s of remaining time.\n",
            "\t-151739980.7768\t = Validation mean_squared_error score\n",
            "\t10.69s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4.62s of the 4.62s of remaining time.\n",
            "\t-4843.9028\t = Validation mean_squared_error score\n",
            "\t1.51s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 3.08s of the 3.08s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetMXNet_BAG_L1.\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2.7s of the 2.69s of remaining time.\n",
            "\t-8917.2372\t = Validation mean_squared_error score\n",
            "\t1.89s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.9s of the 0.76s of remaining time.\n",
            "\t-2825.6483\t = Validation mean_squared_error score\n",
            "\t0.32s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 29.57s ...\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
            "\t-4187.5242\t = Validation mean_squared_error score\n",
            "\t0.65s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t0.14s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL ...\n",
            "\t-2825.6483\t = Validation mean_squared_error score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Deleting model LightGBMXT_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/LightGBMXT_BAG_L1/ will be removed.\n",
            "Deleting model LightGBM_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/LightGBM_BAG_L1/ will be removed.\n",
            "Deleting model RandomForestMSE_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/RandomForestMSE_BAG_L1/ will be removed.\n",
            "Deleting model CatBoost_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/CatBoost_BAG_L1/ will be removed.\n",
            "Deleting model ExtraTreesMSE_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/ExtraTreesMSE_BAG_L1/ will be removed.\n",
            "Deleting model NeuralNetFastAI_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/NeuralNetFastAI_BAG_L1/ will be removed.\n",
            "Deleting model XGBoost_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/XGBoost_BAG_L1/ will be removed.\n",
            "Deleting model LightGBMLarge_BAG_L1. All files under AutogluonModels/ag-20210715_083920/models/LightGBMLarge_BAG_L1/ will be removed.\n",
            "Deleting model WeightedEnsemble_L2. All files under AutogluonModels/ag-20210715_083920/models/WeightedEnsemble_L2/ will be removed.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_083920/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_083951/\"\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_083951/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12597.52 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 160, Val Rows: 40\n",
            "Fitting model: LightGBM ... Training model for up to 29.9s of the 29.9s of remaining time.\n",
            "\t-24968.8412\t = Validation mean_squared_error score\n",
            "\t0.34s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.54s of the 29.53s of remaining time.\n",
            "\t-27383.6857\t = Validation mean_squared_error score\n",
            "\t0.46s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 29.02s of the 29.01s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 2738.6\tvalid_set's l2: 28725.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-65212.4328\t = Validation mean_squared_error score\n",
            "\t1.26s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 27.75s of the 27.75s of remaining time.\n",
            "\t-156677121.9703\t = Validation mean_squared_error score\n",
            "\t2.52s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 25.19s of the 25.18s of remaining time.\n",
            "\t-5679.4296\t = Validation mean_squared_error score\n",
            "\t0.26s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet ... Training model for up to 24.89s of the 24.89s of remaining time.\n",
            "\t-89005.9195\t = Validation mean_squared_error score\n",
            "\t2.75s\t = Training runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.9s of the 21.63s of remaining time.\n",
            "\t-5191.778\t = Validation mean_squared_error score\n",
            "\t0.22s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.63s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_083951/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_083959/\"\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_083959/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15917.532072521899, 7988.390033328879, 12288.70726, 2106.16103)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12597.35 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 160, Val Rows: 40\n",
            "Excluded Model Types: ['KNN', 'NN', 'custom']\n",
            "\tFound 'NN' model in hyperparameters, but 'NN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.86s of the 29.85s of remaining time.\n",
            "\t-27383.6857\t = Validation mean_squared_error score\n",
            "\t0.49s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 29.32s of the 29.31s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 2738.6\tvalid_set's l2: 28725.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-24968.8412\t = Validation mean_squared_error score\n",
            "\t0.3s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ... Training model for up to 29.0s of the 28.99s of remaining time.\n",
            "\t-4677.4179\t = Validation mean_squared_error score\n",
            "\t0.74s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 28.12s of the 28.11s of remaining time.\n",
            "\t-65212.4328\t = Validation mean_squared_error score\n",
            "\t1.27s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ... Training model for up to 26.83s of the 26.82s of remaining time.\n",
            "\t-2974.5727\t = Validation mean_squared_error score\n",
            "\t0.65s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 26.05s of the 26.04s of remaining time.\n",
            "\t-156775531.835\t = Validation mean_squared_error score\n",
            "\t2.54s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 23.47s of the 23.46s of remaining time.\n",
            "\t-5679.4296\t = Validation mean_squared_error score\n",
            "\t0.26s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 23.17s of the 23.16s of remaining time.\n",
            "\t-4242.3849\t = Validation mean_squared_error score\n",
            "\t0.39s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.86s of the 22.38s of remaining time.\n",
            "\t-1783.2037\t = Validation mean_squared_error score\n",
            "\t0.29s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.94s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_083959/\")\n",
            "Loaded data from: train_NFL.csv | Columns = 20 / 20 | Rows = 250 -> 250\n",
            "Loaded data from: test_NFL.csv | Columns = 20 / 20 | Rows = 108 -> 108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfl_data</th>\n",
              "      <th>NFO</th>\n",
              "      <th>NFL</th>\n",
              "      <th>NFC</th>\n",
              "      <th>FIIB</th>\n",
              "      <th>FIIS</th>\n",
              "      <th>FIIN</th>\n",
              "      <th>DIIB</th>\n",
              "      <th>DIIS</th>\n",
              "      <th>DIIN</th>\n",
              "      <th>August</th>\n",
              "      <th>December</th>\n",
              "      <th>CAD</th>\n",
              "      <th>DAD</th>\n",
              "      <th>DOD</th>\n",
              "      <th>NDAD</th>\n",
              "      <th>Currey</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Shine</th>\n",
              "      <th>Vega</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>322</td>\n",
              "      <td>14912.300728</td>\n",
              "      <td>14880.184447</td>\n",
              "      <td>14930.574520</td>\n",
              "      <td>6577.06</td>\n",
              "      <td>6913.06</td>\n",
              "      <td>-336.00</td>\n",
              "      <td>5172.16</td>\n",
              "      <td>5848.83</td>\n",
              "      <td>-676.67</td>\n",
              "      <td>1182.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.3307</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-3.80</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>356</td>\n",
              "      <td>15858.319680</td>\n",
              "      <td>15770.343345</td>\n",
              "      <td>15787.255763</td>\n",
              "      <td>6057.48</td>\n",
              "      <td>7704.14</td>\n",
              "      <td>-1646.66</td>\n",
              "      <td>6171.14</td>\n",
              "      <td>4650.96</td>\n",
              "      <td>1520.18</td>\n",
              "      <td>965.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.3200</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.05</td>\n",
              "      <td>0.0520</td>\n",
              "      <td>-0.0300</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.190001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>325</td>\n",
              "      <td>14801.460633</td>\n",
              "      <td>14650.134598</td>\n",
              "      <td>14719.921036</td>\n",
              "      <td>5797.54</td>\n",
              "      <td>8053.38</td>\n",
              "      <td>-2255.84</td>\n",
              "      <td>7096.88</td>\n",
              "      <td>5148.40</td>\n",
              "      <td>1948.48</td>\n",
              "      <td>1340.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.0233</td>\n",
              "      <td>1.08</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>0.0620</td>\n",
              "      <td>0.2854</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>58</td>\n",
              "      <td>7974.231093</td>\n",
              "      <td>7878.552697</td>\n",
              "      <td>8295.567609</td>\n",
              "      <td>8999.97</td>\n",
              "      <td>8644.19</td>\n",
              "      <td>355.78</td>\n",
              "      <td>5594.30</td>\n",
              "      <td>3890.58</td>\n",
              "      <td>1703.72</td>\n",
              "      <td>1028.0</td>\n",
              "      <td>811.0</td>\n",
              "      <td>-2.76</td>\n",
              "      <td>-0.5180</td>\n",
              "      <td>-1.12</td>\n",
              "      <td>-1.04</td>\n",
              "      <td>0.5825</td>\n",
              "      <td>-0.0056</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>4.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>151</td>\n",
              "      <td>11310.893400</td>\n",
              "      <td>11162.686702</td>\n",
              "      <td>11251.213943</td>\n",
              "      <td>5409.49</td>\n",
              "      <td>4274.92</td>\n",
              "      <td>1134.57</td>\n",
              "      <td>2893.29</td>\n",
              "      <td>3272.67</td>\n",
              "      <td>-379.38</td>\n",
              "      <td>1325.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>0.1350</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.1200</td>\n",
              "      <td>-0.0700</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>13</td>\n",
              "      <td>12376.112958</td>\n",
              "      <td>12355.358743</td>\n",
              "      <td>12387.732631</td>\n",
              "      <td>6095.57</td>\n",
              "      <td>6145.65</td>\n",
              "      <td>-50.08</td>\n",
              "      <td>3255.07</td>\n",
              "      <td>3562.88</td>\n",
              "      <td>-307.81</td>\n",
              "      <td>787.0</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>-0.31</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.1050</td>\n",
              "      <td>-0.0951</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>79</td>\n",
              "      <td>9675.136160</td>\n",
              "      <td>9491.016129</td>\n",
              "      <td>9551.701229</td>\n",
              "      <td>3699.65</td>\n",
              "      <td>4759.04</td>\n",
              "      <td>-1059.39</td>\n",
              "      <td>3351.43</td>\n",
              "      <td>4346.73</td>\n",
              "      <td>-995.30</td>\n",
              "      <td>597.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>-1.28</td>\n",
              "      <td>-0.0200</td>\n",
              "      <td>0.31</td>\n",
              "      <td>2.70</td>\n",
              "      <td>0.0757</td>\n",
              "      <td>0.7800</td>\n",
              "      <td>0.81</td>\n",
              "      <td>-2.360001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>86</td>\n",
              "      <td>9302.322865</td>\n",
              "      <td>9163.548507</td>\n",
              "      <td>9192.657280</td>\n",
              "      <td>3905.69</td>\n",
              "      <td>6293.73</td>\n",
              "      <td>-2388.04</td>\n",
              "      <td>3501.57</td>\n",
              "      <td>2276.04</td>\n",
              "      <td>1225.53</td>\n",
              "      <td>837.0</td>\n",
              "      <td>945.0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.05</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.3163</td>\n",
              "      <td>0.2150</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-0.720001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>10936.474761</td>\n",
              "      <td>10900.465863</td>\n",
              "      <td>11005.399713</td>\n",
              "      <td>8209.13</td>\n",
              "      <td>5943.25</td>\n",
              "      <td>2265.88</td>\n",
              "      <td>3465.53</td>\n",
              "      <td>4192.92</td>\n",
              "      <td>-727.39</td>\n",
              "      <td>1030.0</td>\n",
              "      <td>848.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.74</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.2538</td>\n",
              "      <td>0.3229</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.380001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>253</td>\n",
              "      <td>14551.584522</td>\n",
              "      <td>14517.302013</td>\n",
              "      <td>14655.403965</td>\n",
              "      <td>9104.25</td>\n",
              "      <td>7489.59</td>\n",
              "      <td>1614.66</td>\n",
              "      <td>5053.57</td>\n",
              "      <td>6093.05</td>\n",
              "      <td>-1039.48</td>\n",
              "      <td>601.0</td>\n",
              "      <td>1369.0</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.1150</td>\n",
              "      <td>-1.01</td>\n",
              "      <td>-2.27</td>\n",
              "      <td>0.0405</td>\n",
              "      <td>-0.0240</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.260000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     nfl_data           NFO           NFL  ...    Flow  Shine      Vega\n",
              "172       322  14912.300728  14880.184447  ...  0.1900   0.02  2.180000\n",
              "47        356  15858.319680  15770.343345  ... -0.0300   0.15 -0.190001\n",
              "117       325  14801.460633  14650.134598  ...  0.2854   1.25  0.910000\n",
              "192        58   7974.231093   7878.552697  ... -0.0056  -0.34  4.540001\n",
              "67        151  11310.893400  11162.686702  ... -0.0700  -0.09  0.160000\n",
              "..        ...           ...           ...  ...     ...    ...       ...\n",
              "30         13  12376.112958  12355.358743  ... -0.0951   0.40  0.750000\n",
              "24         79   9675.136160   9491.016129  ...  0.7800   0.81 -2.360001\n",
              "125        86   9302.322865   9163.548507  ...  0.2150   0.90 -0.720001\n",
              "2         131  10936.474761  10900.465863  ...  0.3229   0.11  0.380001\n",
              "3         253  14551.584522  14517.302013  ... -0.0240  -0.15 -0.260000\n",
              "\n",
              "[200 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfl_data</th>\n",
              "      <th>NFO</th>\n",
              "      <th>NFL</th>\n",
              "      <th>NFC</th>\n",
              "      <th>FIIB</th>\n",
              "      <th>FIIS</th>\n",
              "      <th>FIIN</th>\n",
              "      <th>DIIB</th>\n",
              "      <th>DIIS</th>\n",
              "      <th>DIIN</th>\n",
              "      <th>August</th>\n",
              "      <th>December</th>\n",
              "      <th>CAD</th>\n",
              "      <th>DAD</th>\n",
              "      <th>DOD</th>\n",
              "      <th>NDAD</th>\n",
              "      <th>Currey</th>\n",
              "      <th>Flow</th>\n",
              "      <th>Shine</th>\n",
              "      <th>Vega</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74</td>\n",
              "      <td>9224.787826</td>\n",
              "      <td>9209.218348</td>\n",
              "      <td>9265.455350</td>\n",
              "      <td>3888.01</td>\n",
              "      <td>4804.43</td>\n",
              "      <td>-916.42</td>\n",
              "      <td>4502.75</td>\n",
              "      <td>3360.78</td>\n",
              "      <td>1141.97</td>\n",
              "      <td>1085.0</td>\n",
              "      <td>762.0</td>\n",
              "      <td>1.99</td>\n",
              "      <td>0.6440</td>\n",
              "      <td>1.32</td>\n",
              "      <td>6.00</td>\n",
              "      <td>-0.0530</td>\n",
              "      <td>-0.6500</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-2.639999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>182</td>\n",
              "      <td>11316.398544</td>\n",
              "      <td>11301.813485</td>\n",
              "      <td>11368.048610</td>\n",
              "      <td>5685.56</td>\n",
              "      <td>5448.85</td>\n",
              "      <td>236.71</td>\n",
              "      <td>2779.65</td>\n",
              "      <td>3251.21</td>\n",
              "      <td>-471.56</td>\n",
              "      <td>1041.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>1.72</td>\n",
              "      <td>0.3288</td>\n",
              "      <td>2.47</td>\n",
              "      <td>0.95</td>\n",
              "      <td>-0.1560</td>\n",
              "      <td>0.2925</td>\n",
              "      <td>0.11</td>\n",
              "      <td>1.259998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>193</td>\n",
              "      <td>11892.974083</td>\n",
              "      <td>11795.553365</td>\n",
              "      <td>11855.629646</td>\n",
              "      <td>6335.73</td>\n",
              "      <td>4750.66</td>\n",
              "      <td>1585.07</td>\n",
              "      <td>2928.16</td>\n",
              "      <td>4561.39</td>\n",
              "      <td>-1633.23</td>\n",
              "      <td>976.0</td>\n",
              "      <td>883.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.1220</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>167</td>\n",
              "      <td>11293.943187</td>\n",
              "      <td>11255.865945</td>\n",
              "      <td>11365.174861</td>\n",
              "      <td>5468.87</td>\n",
              "      <td>4293.06</td>\n",
              "      <td>1175.81</td>\n",
              "      <td>3004.57</td>\n",
              "      <td>3728.88</td>\n",
              "      <td>-724.31</td>\n",
              "      <td>982.0</td>\n",
              "      <td>869.0</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.2153</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>0.0991</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-2.839998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34</td>\n",
              "      <td>12092.498775</td>\n",
              "      <td>12015.261661</td>\n",
              "      <td>12095.001657</td>\n",
              "      <td>7632.11</td>\n",
              "      <td>6136.86</td>\n",
              "      <td>1495.25</td>\n",
              "      <td>3768.28</td>\n",
              "      <td>4467.90</td>\n",
              "      <td>-699.62</td>\n",
              "      <td>929.0</td>\n",
              "      <td>906.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.3000</td>\n",
              "      <td>1.20</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>0.0670</td>\n",
              "      <td>0.0676</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>1.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>25</td>\n",
              "      <td>11858.873496</td>\n",
              "      <td>11825.694347</td>\n",
              "      <td>11990.125172</td>\n",
              "      <td>6251.69</td>\n",
              "      <td>6812.05</td>\n",
              "      <td>-560.36</td>\n",
              "      <td>4545.19</td>\n",
              "      <td>4241.18</td>\n",
              "      <td>304.01</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>764.0</td>\n",
              "      <td>-0.42</td>\n",
              "      <td>0.0720</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.0386</td>\n",
              "      <td>0.33</td>\n",
              "      <td>-0.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>311</td>\n",
              "      <td>14249.837981</td>\n",
              "      <td>14112.258235</td>\n",
              "      <td>14323.232058</td>\n",
              "      <td>6729.46</td>\n",
              "      <td>8090.22</td>\n",
              "      <td>-1360.76</td>\n",
              "      <td>5151.62</td>\n",
              "      <td>3456.03</td>\n",
              "      <td>1695.59</td>\n",
              "      <td>1028.0</td>\n",
              "      <td>864.0</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>1.18</td>\n",
              "      <td>2.75</td>\n",
              "      <td>-0.1010</td>\n",
              "      <td>0.1987</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-1.379999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>2</td>\n",
              "      <td>12195.406448</td>\n",
              "      <td>12173.355954</td>\n",
              "      <td>12251.196928</td>\n",
              "      <td>4514.35</td>\n",
              "      <td>3251.30</td>\n",
              "      <td>1263.05</td>\n",
              "      <td>2750.87</td>\n",
              "      <td>3780.07</td>\n",
              "      <td>-1029.20</td>\n",
              "      <td>879.0</td>\n",
              "      <td>973.0</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.5100</td>\n",
              "      <td>-1.33</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.4430</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>285</td>\n",
              "      <td>15051.353313</td>\n",
              "      <td>14951.637063</td>\n",
              "      <td>15074.673461</td>\n",
              "      <td>6534.99</td>\n",
              "      <td>6550.68</td>\n",
              "      <td>-15.69</td>\n",
              "      <td>4059.79</td>\n",
              "      <td>3612.12</td>\n",
              "      <td>447.67</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>851.0</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.2150</td>\n",
              "      <td>1.83</td>\n",
              "      <td>-2.10</td>\n",
              "      <td>-0.0305</td>\n",
              "      <td>0.2607</td>\n",
              "      <td>0.13</td>\n",
              "      <td>-1.470001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>88</td>\n",
              "      <td>9151.830603</td>\n",
              "      <td>8861.363959</td>\n",
              "      <td>8890.294356</td>\n",
              "      <td>13613.73</td>\n",
              "      <td>14942.04</td>\n",
              "      <td>-1328.31</td>\n",
              "      <td>4362.13</td>\n",
              "      <td>2702.39</td>\n",
              "      <td>1659.74</td>\n",
              "      <td>788.0</td>\n",
              "      <td>982.0</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>-0.2100</td>\n",
              "      <td>-1.10</td>\n",
              "      <td>-2.31</td>\n",
              "      <td>-0.1070</td>\n",
              "      <td>-0.0900</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.230001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    nfl_data           NFO           NFL  ...    Flow  Shine      Vega\n",
              "0         74   9224.787826   9209.218348  ... -0.6500  -0.17 -2.639999\n",
              "1        182  11316.398544  11301.813485  ...  0.2925   0.11  1.259998\n",
              "2        193  11892.974083  11795.553365  ...  0.1651   0.05  0.170000\n",
              "3        167  11293.943187  11255.865945  ...  0.0991  -0.36 -2.839998\n",
              "4         34  12092.498775  12015.261661  ...  0.0676  -0.23  1.180000\n",
              "..       ...           ...           ...  ...     ...    ...       ...\n",
              "70        25  11858.873496  11825.694347  ...  0.0386   0.33 -0.190000\n",
              "71       311  14249.837981  14112.258235  ...  0.1987  -0.20 -1.379999\n",
              "72         2  12195.406448  12173.355954  ...  0.5648   0.08  1.550000\n",
              "73       285  15051.353313  14951.637063  ...  0.2607   0.13 -1.470001\n",
              "74        88   9151.830603   8861.363959  ... -0.0900   0.90  1.230001\n",
              "\n",
              "[75 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_084008/\"\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_084008/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Tuning Data Rows:    75\n",
            "Tuning Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12598.29 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Hyperparameter tuning model: LightGBM ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "507444a8d1494c789f6160642bf10f29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fitted model: LightGBM/T0 ...\n",
            "\t-18867.8082\t = Validation mean_squared_error score\n",
            "\t0.27s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T1 ...\n",
            "\t-226246.2363\t = Validation mean_squared_error score\n",
            "\t0.21s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T2 ...\n",
            "\t-27432.4105\t = Validation mean_squared_error score\n",
            "\t0.22s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T3 ...\n",
            "\t-29408.7822\t = Validation mean_squared_error score\n",
            "\t0.22s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T4 ...\n",
            "\t-5847.3223\t = Validation mean_squared_error score\n",
            "\t0.24s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetMXNet ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2394c113a0da4fe0becadaf89fdf2a0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fitted model: NeuralNetMXNet/T0 ...\n",
            "\t-4137595.75\t = Validation mean_squared_error score\n",
            "\t0.3s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T1 ...\n",
            "\t-4170367.5\t = Validation mean_squared_error score\n",
            "\t0.31s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T2 ...\n",
            "\t-3782988.0\t = Validation mean_squared_error score\n",
            "\t0.32s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T3 ...\n",
            "\t-4334399.0\t = Validation mean_squared_error score\n",
            "\t0.33s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: NeuralNetMXNet/T4 ...\n",
            "\t-3200803.5\t = Validation mean_squared_error score\n",
            "\t0.25s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.9s of the 110.96s of remaining time.\n",
            "\t-5707.7493\t = Validation mean_squared_error score\n",
            "\t0.39s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.45s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_084008/\")\n",
            "Evaluation: mean_squared_error on test data: -8310.472689606677\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -8310.472689606677\n",
            "}\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_084017/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_084017/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictions:   [14739.9375, 11175.951171875, 13547.8603515625, 14559.5927734375, 8948.560546875]\n",
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model     score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2 -5.707749e+03       0.006803  0.908009                0.000606           0.392882            2       True         11\n",
            "1           LightGBM/T4 -5.847322e+03       0.003204  0.242947                0.003204           0.242947            1       True          5\n",
            "2           LightGBM/T0 -1.886781e+04       0.002993  0.272180                0.002993           0.272180            1       True          1\n",
            "3           LightGBM/T2 -2.743241e+04       0.003245  0.224458                0.003245           0.224458            1       True          3\n",
            "4           LightGBM/T3 -2.940878e+04       0.002970  0.220292                0.002970           0.220292            1       True          4\n",
            "5           LightGBM/T1 -2.262462e+05       0.002955  0.205940                0.002955           0.205940            1       True          2\n",
            "6     NeuralNetMXNet/T4 -3.200804e+06       0.004080  0.247802                0.004080           0.247802            1       True         10\n",
            "7     NeuralNetMXNet/T2 -3.782988e+06       0.004106  0.322127                0.004106           0.322127            1       True          8\n",
            "8     NeuralNetMXNet/T0 -4.137596e+06       0.004198  0.297345                0.004198           0.297345            1       True          6\n",
            "9     NeuralNetMXNet/T1 -4.170368e+06       0.003882  0.309945                0.003882           0.309945            1       True          7\n",
            "10    NeuralNetMXNet/T3 -4.334399e+06       0.003734  0.334904                0.003734           0.334904            1       True          9\n",
            "Number of models trained: 11\n",
            "Types of models trained:\n",
            "{'LGBModel', 'TabularNeuralNetModel', 'WeightedEnsembleModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "('int', [])   :  1 | ['nfl_data']\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20210715_084008/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12584.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\t-784862.7244\t = Validation mean_squared_error score\n",
            "\t0.95s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
            "\t-5294201.5473\t = Validation mean_squared_error score\n",
            "\t2.24s\t = Training runtime\n",
            "\t0.86s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-784862.7244\t = Validation mean_squared_error score\n",
            "\t0.11s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\t-758430.636\t = Validation mean_squared_error score\n",
            "\t0.88s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
            "\t-5011715.7643\t = Validation mean_squared_error score\n",
            "\t2.32s\t = Training runtime\n",
            "\t0.88s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\t-758430.636\t = Validation mean_squared_error score\n",
            "\t0.1s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.68s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_084017/\")\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"ModelFolderNFL/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12585.05 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.83s of the 29.83s of remaining time.\n",
            "\t-784862.7244\t = Validation mean_squared_error score\n",
            "\t0.9s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 28.88s of the 28.87s of remaining time.\n",
            "\t-5141929.294\t = Validation mean_squared_error score\n",
            "\t2.29s\t = Training runtime\n",
            "\t0.87s\t = Validation runtime\n",
            "Repeating k-fold bagging: 2/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 25.67s of the 25.67s of remaining time.\n",
            "\t-784439.1748\t = Validation mean_squared_error score\n",
            "\t1.79s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 24.73s of the 24.73s of remaining time.\n",
            "\t-5268157.1355\t = Validation mean_squared_error score\n",
            "\t4.56s\t = Training runtime\n",
            "\t1.75s\t = Validation runtime\n",
            "Repeating k-fold bagging: 3/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 21.53s of the 21.53s of remaining time.\n",
            "\t-790982.8617\t = Validation mean_squared_error score\n",
            "\t2.7s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 20.56s of the 20.56s of remaining time.\n",
            "\t-5255784.3\t = Validation mean_squared_error score\n",
            "\t6.83s\t = Training runtime\n",
            "\t2.62s\t = Validation runtime\n",
            "Repeating k-fold bagging: 4/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 17.38s of the 17.38s of remaining time.\n",
            "\t-796981.0889\t = Validation mean_squared_error score\n",
            "\t3.61s\t = Training runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 16.42s of the 16.42s of remaining time.\n",
            "\t-5330192.1226\t = Validation mean_squared_error score\n",
            "\t9.08s\t = Training runtime\n",
            "\t3.49s\t = Validation runtime\n",
            "Repeating k-fold bagging: 5/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 13.26s of the 13.25s of remaining time.\n",
            "\t-796131.074\t = Validation mean_squared_error score\n",
            "\t4.49s\t = Training runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 12.31s of the 12.31s of remaining time.\n",
            "\t-5307935.5796\t = Validation mean_squared_error score\n",
            "\t11.35s\t = Training runtime\n",
            "\t4.35s\t = Validation runtime\n",
            "Repeating k-fold bagging: 6/20\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9.13s of the 9.13s of remaining time.\n",
            "\t-794032.5452\t = Validation mean_squared_error score\n",
            "\t5.38s\t = Training runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 8.18s of the 8.18s of remaining time.\n",
            "\t-5277160.8668\t = Validation mean_squared_error score\n",
            "\t13.62s\t = Training runtime\n",
            "\t5.23s\t = Validation runtime\n",
            "Completed 6/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.83s of the 4.99s of remaining time.\n",
            "\t-794032.5452\t = Validation mean_squared_error score\n",
            "\t0.11s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 25.14s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ModelFolderNFL/\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    nfl_data           NFO           NFC     FIIB  ...  Currey  Flow  Shine  Vega\n",
            "75       274  15068.866844  14786.188427  8112.33  ...  -0.061  0.19  -0.37 -0.34\n",
            "\n",
            "[1 rows x 19 columns]\n",
            "Prediction from LightGBM_BAG_L1 model: 13926.491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation: mean_squared_error on test data: -493681.62682533107\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -493681.62682533107,\n",
            "    \"root_mean_squared_error\": -702.6248122756064,\n",
            "    \"mean_absolute_error\": -579.502284147176,\n",
            "    \"r2\": 0.8586520501766688,\n",
            "    \"pearsonr\": 0.995760020978386,\n",
            "    \"median_absolute_error\": -646.3798818839605\n",
            "}\n",
            "Evaluation: mean_squared_error on test data: -493681.62682533107\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -493681.62682533107,\n",
            "    \"root_mean_squared_error\": -702.6248122756064,\n",
            "    \"mean_absolute_error\": -579.502284147176,\n",
            "    \"r2\": 0.8586520501766688,\n",
            "    \"pearsonr\": 0.995760020978386,\n",
            "    \"median_absolute_error\": -646.3798818839605\n",
            "}\n",
            "Computing feature importance via permutation shuffling for 19 features using 33 rows with 3 shuffle sets...\n",
            "\t7.74s\t= Expected runtime (2.58s per shuffle set)\n",
            "\t0.59s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n",
            "Persisting 2 models in memory. Models will require 0.0% of memory.\n",
            "Evaluation: mean_squared_error on test data: -482389.33874500915\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_squared_error\": -482389.33874500915,\n",
            "    \"root_mean_squared_error\": NaN,\n",
            "    \"mean_absolute_error\": -584.7334854682211,\n",
            "    \"r2\": 0.8707319199094755,\n",
            "    \"pearsonr\": 0.9944036255263212,\n",
            "    \"median_absolute_error\": -607.9418720210797\n",
            "}\n",
            "Unpersisted 2 models: ['WeightedEnsemble_L2', 'LightGBM_BAG_L1']\n",
            "Fitting model: WeightedEnsemble_L2Best ...\n",
            "\t-794032.5452\t = Validation mean_squared_error score\n",
            "\t0.09s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictions:  [13926.491 11468.903 13097.033 13736.782 9857.16 10899.033 14186.726\n",
            " 13107.452 11246.748 11887.018 14111.0625 13691.6 13099.257 11845.125\n",
            " 12734.104 12300.876 12776.906 9936.605 11565.5 13646.503]\n",
            "Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting model WeightedEnsemble_L2Best. All files under ModelFolderNFL/models/WeightedEnsemble_L2Best/ will be removed.\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.18s\t = Training runtime\n",
            "Fitting model: NeuralNetMXNet_BAG_L1_FULL ...\n",
            "\t0.25s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL ...\n",
            "\t-794032.5452\t = Validation mean_squared_error score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Name of each refit-full model corresponding to a previous bagged ensemble:\n",
            "{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'NeuralNetMXNet_BAG_L1': 'NeuralNetMXNet_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Distilling with teacher='WeightedEnsemble_L2', teacher_preds=soft, augment_method=spunge ...\n",
            "SPUNGE: Augmenting training data with 800 synthetic samples for distillation...\n",
            "Distilling with each of these student models: ['LightGBM_DSTL', 'NeuralNetMXNet_DSTL', 'CatBoost_DSTL', 'RandomForest_DSTL']\n",
            "Fitting model: LightGBM_DSTL ... Training model for up to 30.0s of the 30.0s of remaining time.\n",
            "\t-624434.5908\t = Validation mean_squared_error score\n",
            "\t0.59s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet_DSTL ... Training model for up to 29.38s of the 29.38s of remaining time.\n",
            "\t-753719.8504\t = Validation mean_squared_error score\n",
            "\t8.57s\t = Training runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: CatBoost_DSTL ... Training model for up to 20.63s of the 20.62s of remaining time.\n",
            "\t-642239.5173\t = Validation mean_squared_error score\n",
            "\t3.17s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForest_DSTL ... Training model for up to 17.44s of the 17.44s of remaining time.\n",
            "\t-471798.8801\t = Validation mean_squared_error score\n",
            "\t1.94s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
            "Fitting model: WeightedEnsemble_L2_DSTL ... Training model for up to 30.0s of the 14.95s of remaining time.\n",
            "\t-471798.8801\t = Validation mean_squared_error score\n",
            "\t0.15s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Distilled model leaderboard:\n",
            "                      model      score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0         RandomForest_DSTL -471798.880075       0.103640  1.939423                0.103640           1.939423            1       True         10\n",
            "1  WeightedEnsemble_L2_DSTL -471798.880075       0.104248  2.090141                0.000607           0.150717            2       True         11\n",
            "2             LightGBM_DSTL -624434.590774       0.004174  0.588177                0.004174           0.588177            1       True          7\n",
            "3             CatBoost_DSTL -642239.517337       0.002228  3.165231                0.002228           3.165231            1       True          9\n",
            "4       NeuralNetMXNet_DSTL -753719.850380       0.183397  8.565493                0.183397           8.565493            1       True          8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['LightGBM_DSTL', 'NeuralNetMXNet_DSTL', 'CatBoost_DSTL', 'RandomForest_DSTL', 'WeightedEnsemble_L2_DSTL']\n",
            "predictions from LightGBM_DSTL: [14025.626953125, 11352.5810546875, 13090.787109375, 13798.5654296875, 9883.8544921875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_084207/\"\n",
            "Presets specified: ['good_quality_faster_inference_only_refit', 'optimize_for_deployment']\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_084207/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12581.19 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 29.85s of the 29.85s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                         model    score_test     score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0            RandomForest_DSTL -3.425652e+05 -4.717989e+05        0.126376       0.103640   1.939423                 0.126376                0.103640           1.939423            1       True         10\n",
            "1     WeightedEnsemble_L2_DSTL -3.425652e+05 -4.717989e+05        0.128464       0.104248   2.090141                 0.002088                0.000607           0.150717            2       True         11\n",
            "2                LightGBM_DSTL -4.194455e+05 -6.244346e+05        0.007643       0.004174   0.588177                 0.007643                0.004174           0.588177            1       True          7\n",
            "3                CatBoost_DSTL -4.360048e+05 -6.422395e+05        0.005657       0.002228   3.165231                 0.005657                0.002228           3.165231            1       True          9\n",
            "4              LightGBM_BAG_L1 -4.936816e+05 -7.940325e+05        0.081862       0.088435   5.380496                 0.081862                0.088435           5.380496            1       True          1\n",
            "5          WeightedEnsemble_L2 -4.936816e+05 -7.940325e+05        0.087655       0.088986   5.487554                 0.005793                0.000551           0.107058            2       True          3\n",
            "6         LightGBM_BAG_L1_FULL -5.011134e+05           NaN        0.003001            NaN   0.177130                 0.003001                     NaN           0.177130            1       True          4\n",
            "7     WeightedEnsemble_L2_FULL -5.011134e+05           NaN        0.004766            NaN   0.180949                 0.001764                0.001340           0.003819            2       True          6\n",
            "8          NeuralNetMXNet_DSTL -6.510182e+05 -7.537199e+05        0.184276       0.183397   8.565493                 0.184276                0.183397           8.565493            1       True          8\n",
            "9        NeuralNetMXNet_BAG_L1 -4.790281e+06 -5.277161e+06        5.573570       5.231934  13.617113                 5.573570                5.231934          13.617113            1       True          2\n",
            "10  NeuralNetMXNet_BAG_L1_FULL -5.371296e+06           NaN        0.185072            NaN   0.254497                 0.185072                     NaN           0.254497            1       True          5\n",
            "[1000]\ttrain_set's l2: 2499.53\tvalid_set's l2: 11852.4\n",
            "[2000]\ttrain_set's l2: 311.24\tvalid_set's l2: 11319.2\n",
            "[1000]\ttrain_set's l2: 3285.41\tvalid_set's l2: 67084.5\n",
            "[2000]\ttrain_set's l2: 343.611\tvalid_set's l2: 64608.8\n",
            "[1000]\ttrain_set's l2: 1264.54\tvalid_set's l2: 80197.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-59569.6533\t = Validation mean_squared_error score\n",
            "\t2.48s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 27.32s of the 27.31s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 30.822\tvalid_set's l2: 49084.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-34769.3143\t = Validation mean_squared_error score\n",
            "\t1.62s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 25.64s of the 25.64s of remaining time.\n",
            "\t-7210.472\t = Validation mean_squared_error score\n",
            "\t0.83s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 24.69s of the 24.69s of remaining time.\n",
            "\t-71306.8056\t = Validation mean_squared_error score\n",
            "\t18.7s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 5.96s of the 5.95s of remaining time.\n",
            "\t-5099.3602\t = Validation mean_squared_error score\n",
            "\t0.65s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.19s of the 5.19s of remaining time.\n",
            "\tRan out of time, stopping training early.\n",
            "\tRan out of time, stopping training early.\n",
            "\tRan out of time, stopping training early.\n",
            "\tRan out of time, stopping training early.\n",
            "\tRan out of time, stopping training early.\n",
            "\t-151700226.754\t = Validation mean_squared_error score\n",
            "\t4.93s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.12s of the 0.12s of remaining time.\n",
            "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 0.09s of the 0.09s of remaining time.\n",
            "\tTime limit exceeded... Skipping NeuralNetMXNet_BAG_L1.\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.85s of the -0.31s of remaining time.\n",
            "\t-5066.9958\t = Validation mean_squared_error score\n",
            "\t0.23s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 30.56s ...\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
            "\t-5099.3602\t = Validation mean_squared_error score\n",
            "\t0.65s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL ...\n",
            "\t-7210.472\t = Validation mean_squared_error score\n",
            "\t0.84s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.37s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 874.412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-5066.9958\t = Validation mean_squared_error score\n",
            "\t0.13s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Deleting model LightGBMXT_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/LightGBMXT_BAG_L1/ will be removed.\n",
            "Deleting model LightGBM_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/LightGBM_BAG_L1/ will be removed.\n",
            "Deleting model RandomForestMSE_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/RandomForestMSE_BAG_L1/ will be removed.\n",
            "Deleting model CatBoost_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/CatBoost_BAG_L1/ will be removed.\n",
            "Deleting model ExtraTreesMSE_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/ExtraTreesMSE_BAG_L1/ will be removed.\n",
            "Deleting model NeuralNetFastAI_BAG_L1. All files under AutogluonModels/ag-20210715_084207/models/NeuralNetFastAI_BAG_L1/ will be removed.\n",
            "Deleting model WeightedEnsemble_L2. All files under AutogluonModels/ag-20210715_084207/models/WeightedEnsemble_L2/ will be removed.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_084207/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_084240/\"\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_084240/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12552.85 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 160, Val Rows: 40\n",
            "Fitting model: LightGBM ... Training model for up to 29.85s of the 29.84s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 27.7168\tvalid_set's l2: 33637.1\n",
            "[2000]\ttrain_set's l2: 0.0305429\tvalid_set's l2: 33239\n",
            "[3000]\ttrain_set's l2: 5.02656e-05\tvalid_set's l2: 33235.3\n",
            "[4000]\ttrain_set's l2: 5.70207e-07\tvalid_set's l2: 33234.9\n",
            "[5000]\ttrain_set's l2: 3.74396e-08\tvalid_set's l2: 33234.9\n",
            "[6000]\ttrain_set's l2: 2.44957e-09\tvalid_set's l2: 33234.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-33234.8673\t = Validation mean_squared_error score\n",
            "\t2.18s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 27.28s of the 27.27s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 2900.52\tvalid_set's l2: 66197.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-64970.9671\t = Validation mean_squared_error score\n",
            "\t0.51s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 26.71s of the 26.71s of remaining time.\n",
            "\t-78609.711\t = Validation mean_squared_error score\n",
            "\t1.8s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 24.89s of the 24.88s of remaining time.\n",
            "\t-136651061.5378\t = Validation mean_squared_error score\n",
            "\t2.52s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 22.33s of the 22.32s of remaining time.\n",
            "\t-4573.7608\t = Validation mean_squared_error score\n",
            "\t0.29s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet ... Training model for up to 21.99s of the 21.99s of remaining time.\n",
            "\t-126747.6301\t = Validation mean_squared_error score\n",
            "\t2.86s\t = Training runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.85s of the 18.56s of remaining time.\n",
            "\t-4573.7608\t = Validation mean_squared_error score\n",
            "\t0.24s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.71s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_084240/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210715_084252/\"\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210715_084252/\"\n",
            "AutoGluon Version:  0.2.0\n",
            "Train Data Rows:    200\n",
            "Train Data Columns: 19\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (15804.933349617, 7264.76863366667, 12141.01321, 2288.89135)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12550.69 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 18 | ['NFO', 'NFC', 'FIIB', 'FIIS', 'FIIN', ...]\n",
            "\t\t('int', [])   :  1 | ['nfl_data']\n",
            "\t0.1s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 160, Val Rows: 40\n",
            "Excluded Model Types: ['KNN', 'NN', 'custom']\n",
            "\tFound 'NN' model in hyperparameters, but 'NN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.82s of the 29.8s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 2900.52\tvalid_set's l2: 66197.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-64970.9671\t = Validation mean_squared_error score\n",
            "\t0.55s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 29.19s of the 29.17s of remaining time.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 27.7168\tvalid_set's l2: 33637.1\n",
            "[2000]\ttrain_set's l2: 0.0305429\tvalid_set's l2: 33239\n",
            "[3000]\ttrain_set's l2: 5.02656e-05\tvalid_set's l2: 33235.3\n",
            "[4000]\ttrain_set's l2: 5.70207e-07\tvalid_set's l2: 33234.9\n",
            "[5000]\ttrain_set's l2: 3.74396e-08\tvalid_set's l2: 33234.9\n",
            "[6000]\ttrain_set's l2: 2.44957e-09\tvalid_set's l2: 33234.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t-33234.8673\t = Validation mean_squared_error score\n",
            "\t2.2s\t = Training runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ... Training model for up to 26.62s of the 26.6s of remaining time.\n",
            "\t-9403.1067\t = Validation mean_squared_error score\n",
            "\t0.74s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 25.74s of the 25.72s of remaining time.\n",
            "\t-78609.711\t = Validation mean_squared_error score\n",
            "\t1.82s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ... Training model for up to 23.91s of the 23.9s of remaining time.\n",
            "\t-6496.9983\t = Validation mean_squared_error score\n",
            "\t0.66s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 23.12s of the 23.1s of remaining time.\n",
            "\t-136655931.0981\t = Validation mean_squared_error score\n",
            "\t2.75s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 20.32s of the 20.3s of remaining time.\n",
            "\t-4573.7608\t = Validation mean_squared_error score\n",
            "\t0.34s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 19.94s of the 19.92s of remaining time.\n",
            "\t-13032.3102\t = Validation mean_squared_error score\n",
            "\t0.86s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.82s of the 18.45s of remaining time.\n",
            "\t-4325.4339\t = Validation mean_squared_error score\n",
            "\t0.31s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.91s ...\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210715_084252/\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alWNWgr2V7ic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
